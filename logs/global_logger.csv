id,model,parameters,columns,transformers,column_transforms,valid_strategy,one_fold,observation,post_accuracy,post_precision,post_recall,post_error,user_accuracy,user_precision,user_recall,user_error
0,<class 'lightgbm.sklearn.LGBMClassifier'>,{'random_state': 42},['text'],"[{'name': 'word_tfidf', 'algorithm': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, 'parameters': {'analyzer': 'word', 'ngram_range': (1, 1)}, 'columns': 'text'}]","{'remainder': 'drop', 'n_jobs': -1}",1,True,Baseline,0.276,0.456,0.413,0.161,0.22899999999999998,0.47100000000000003,0.308,0.22899999999999998
1,<class 'sklearn.svm._classes.SVC'>,{'random_state': 42},['text'],"[{'name': 'word_tfidf', 'algorithm': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, 'parameters': {'analyzer': 'word', 'ngram_range': (1, 1)}, 'columns': 'text'}]","{'remainder': 'drop', 'n_jobs': -1}",1,True,Baseline,0.259,0.436,0.389,0.168,0.229,0.421,0.333,0.229
2,<class 'sklearn.ensemble._forest.RandomForestClassifier'>,{'random_state': 42},['text'],"[{'name': 'word_tfidf', 'algorithm': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, 'parameters': {'analyzer': 'word', 'ngram_range': (1, 1)}, 'columns': 'text'}]","{'remainder': 'drop', 'n_jobs': -1}",1,True,Baseline,0.24600000000000002,0.401,0.389,0.15,0.2,0.35,0.318,0.2
3,<class 'lightgbm.sklearn.LGBMClassifier'>,{'random_state': 42},['text'],"[{'name': 'word_tfidf', 'algorithm': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, 'parameters': {'analyzer': 'word', 'ngram_range': (1, 5), 'max_features': None, 'token_pattern': '(?u)\\b\\w\\w+\\b|!|,|.|\\?|\\""|\\\''}, 'columns': 'text'}]","{'remainder': 'drop', 'n_jobs': -1}",1,True,"Punctuation in TF-IDF, Ngrams 1-5",0.285,0.463,0.426,0.171,0.314,0.611,0.393,0.229
4,<class 'lightgbm.sklearn.LGBMClassifier'>,{'random_state': 42},"['text', 'happy', 'angry', 'surprise', 'sad', 'fear']","[{'name': 'word_tfidf', 'algorithm': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, 'parameters': {'analyzer': 'word', 'ngram_range': (1, 5), 'max_features': None, 'token_pattern': '(?u)\\b\\w\\w+\\b|!|,|.|\\?|\\""|\\\''}, 'columns': 'text'}]","{'remainder': StandardScaler(copy=True, with_mean=True, with_std=True), 'n_jobs': -1}",1,True,"Punctuation in TF-IDF, Added Emotion Fetures Standardized, Ngrams 1-5",0.285,0.466,0.42200000000000004,0.17300000000000001,0.34299999999999997,0.667,0.414,0.22899999999999998
5,<class 'sklearn.svm._classes.SVC'>,{'random_state': 42},"['text', 'happy', 'angry', 'surprise', 'sad', 'fear']","[{'name': 'word_tfidf', 'algorithm': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, 'parameters': {'analyzer': 'word', 'ngram_range': (1, 5), 'max_features': None, 'token_pattern': '(?u)\\b\\w\\w+\\b|!|,|.|\\?|\\""|\\\''}, 'columns': 'text'}]","{'remainder': StandardScaler(copy=True, with_mean=True, with_std=True), 'n_jobs': -1}",1,True,"Punctuation in TF-IDF, Added Emotion Fetures Standardized, Ngrams 1-5",0.207,0.305,0.39,0.103,0.2,0.333,0.333,0.2
6,<class 'lightgbm.sklearn.LGBMClassifier'>,"{'n_estimators': 300, 'random_state': 42}","['text', 'happy', 'angry', 'surprise', 'sad', 'fear']","[{'name': 'word_tfidf', 'algorithm': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, 'parameters': {'analyzer': 'word', 'ngram_range': (1, 5), 'max_features': None, 'token_pattern': '(?u)\\b\\w\\w+\\b|!|,|.|\\?|\\""|\\\''}, 'columns': 'text'}]","{'remainder': StandardScaler(copy=True, with_mean=True, with_std=True), 'n_jobs': -1}",1,True,"Punctuation in TF-IDF, Added Emotion Fetures Standardized, Ngrams 1-5",0.28300000000000003,0.455,0.429,0.17600000000000002,0.371,0.684,0.44799999999999995,0.22899999999999998
7,<class 'lightgbm.sklearn.LGBMClassifier'>,"{'n_estimators': 300, 'random_state': 42, 'num_leaves': 64, 'colsample_bytree': 0.8}",['text'],"[{'name': 'word_tfidf', 'algorithm': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, 'parameters': {'analyzer': 'word', 'ngram_range': (1, 5)}, 'columns': 'text'}]","{'remainder': StandardScaler(copy=True, with_mean=True, with_std=True), 'n_jobs': -1}",1,True,From Bayesian Optimization,0.285,0.451,0.435,0.178,0.4,0.667,0.5,0.229
